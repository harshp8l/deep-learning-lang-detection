import org.apache.spark.sql.SQLContext
import org.apache.spark.sql.types.{StructType, StructField, StringType, DoubleType};

val sqlContext = new SQLContext(sc)
val customSchema = StructType(Array(
  StructField(""_id"", StringType, nullable = true),
  StructField(""author"", StringType, nullable = true),
  StructField(""description"", StringType, nullable = true),
  StructField(""genre"", StringType ,nullable = true),
  StructField(""price"", DoubleType, nullable = true),
  StructField(""publish_date"", StringType, nullable = true),
  StructField(""title"", StringType, nullable = true)))


val df = sqlContext.read
  .format(""com.databricks.spark.xml"")
  .option(""rowTag"", ""book"")
  .schema(customSchema)
  .load(""books.xml"")

val selectedData = df.select(""author"", ""_id"")
selectedData.write
  .format(""com.databricks.spark.xml"")
  .option(""rootTag"", ""books"")
  .option(""rowTag"", ""book"")
  .save(""newbooks.xml"")
