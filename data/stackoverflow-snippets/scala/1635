// read Spark Output Fixed width table:
def readSparkOutput(filePath: String) : org.apache.spark.sql.DataFrame = {
    val t = spark.read
                 .option(""header"",""true"")
                 .option(""inferSchema"",""true"")
                 .option(""delimiter"",""|"")
                 .option(""parserLib"",""UNIVOCITY"")
                 .option(""ignoreLeadingWhiteSpace"",""true"")
                 .option(""ignoreTrailingWhiteSpace"",""true"")
                 .option(""comment"",""+"")
                 .csv(filePath)
    t.select(t.columns.filterNot(_.startsWith(""_c"")).map(t(_)):_*)
}
