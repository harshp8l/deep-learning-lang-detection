package dataframe

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.SQLContext
import org.apache.spark.sql.{SQLContext, SparkSession}
import org.apache.spark.{SparkConf, SparkContext}
/**
 * @author vaquar.khan@gmail.com
 */
object Test {

  case class table1Class(key: String, value: String)
  case class table2Class(key: String, value: String, value1: String)
  def main(args: Array[String]) {
    val spark =
      SparkSession.builder()
        .appName("DataFrame-Basic")
        .master("local[4]")
        .getOrCreate()

    import spark.implicits._
    //
    val table1 = Seq(
      table1Class("1", "a"), table1Class("2", "b"), table1Class("3", "c"))

    val df1 = spark.sparkContext.parallelize(table1, 4).toDF()

    df1.show()

    val table2 = Seq(
      table2Class("1", "2", "d"), table2Class("1", "3", "e"))

    val df2 = spark.sparkContext.parallelize(table2, 4).toDF()

    df2.show()
   //
    df1.createOrReplaceTempView("A")
    df2.createOrReplaceTempView("B")

    spark.sql("select d1.key,d1.value,d2.value1  from A d1  inner join B d2 on d1.key = d2.key").show()
 //TODO
 /* need to fix query
    spark.sql( "select * from (  "+ //B1.value,B1.value1,A.value
                     " select A.value,B.value,B.value1 "+
                           " from B "+
                                " left join A "+
                                     " on B.key = A.key ) B2 "+
                                             " left join A " +
                                                 " on B2.value = A.key" ).show()

          */                                       
  }
}
