import org.apache.spark.ml.feature._

val df = Seq(
  745, 1053, 1915, 1755, 832, 630, 820, 945,
  1245, 1645, 620, 1125, 2045, 1340, 1540, 730,
  1145, 525, 630, 1520
).toDF(""CRSDepTime"")

val bucketizer = new Bucketizer()
  .setInputCol(""CRSDepTime"")
  .setOutputCol(""bucketedFeatures"")
  .setSplits(Array(0, 600, 1200, 1800, 2400))

// +----------+----------------+
// |CRSDepTime|bucketedFeatures|
// +----------+----------------+
// |       745|             1.0|
// |      1053|             1.0|
// |      1915|             3.0|
// |      1755|             2.0|
// |       832|             1.0|
// |       630|             1.0|
// |       820|             1.0|
// |       945|             1.0|
// |      1245|             2.0|
// |      1645|             2.0|
// +----------+----------------+
// only showing top 10 rows
