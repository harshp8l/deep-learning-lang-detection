import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.col

object ColumnNameChange {
  def main(args: Array[String]): Unit = {

    val spark = SparkSession
      .builder()
      .appName("SparkSessionExample")
      .config("spark.master", "local")
      .getOrCreate()

    import spark.implicits._

    val df1 = Seq((1, 2, 3, 4)).toDF("A","B","C","D")
    val df2 = Seq(("A", "E"),("B","Q"), ("C", "R"),("D","Z")).toDF("Col1","Col2")


    val name_dict : scala.collection.Map[String,String] = df2.map(row => { row.getAs[String]("Col1") -> row.getAs[String]("Col2") }).collectAsMap()

    val df3 = df1.select(df1.columns.map(c => col(c).as(name_dict.getOrElse(c, c))): _*)
    df3.show()


  }

}
