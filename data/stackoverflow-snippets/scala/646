val df = Seq(
  ("abc", 100), ("bcd", 90), ("abc", 110),
  ("eee", 90), ("eee", 100), ("fff", 95)
).toDF("dep code", "salary")

import org.apache.spark.sql.expressions.Window

df.withColumn("average", avg($"salary").over(Window.partitionBy($"dep code"))).
  withColumn("rank", rank.over(Window.orderBy($"average"))).
  show
// +-------+------+-------+----+
// |dep code|salary|average|rank|
// +--------+------+-------+----+
// |     bcd|    90|   90.0|   1|
// |     fff|    95|   95.0|   2|
// |     eee|    90|   95.0|   2|
// |     eee|   100|   95.0|   2|
// |     abc|   100|  105.0|   5|
// |     abc|   110|  105.0|   5|
// +--------+------+-------+----+
