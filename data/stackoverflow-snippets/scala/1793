import org.apache.spark.sql.functions.{struct, udf}
import org.apache.spark.sql.Row

val f = udf((row: Row) => for {
  // Use Options to avoid problems with null columns
  // Explicit null checks should be faster, but much more verbose
  c1 <- Option(row.getAs[String]("c1"))
  c2 <- Option(row.getAs[String]("c2"))

  // In this case we could (probably) skip Options below
  // but Ints in Spark SQL can get null
  x <- Option(row.getAs[Int](c1))
  y <- Option(row.getAs[Int](c2))
} yield x + y)

df.withColumn("c6", f(struct(df.columns map col: _*)))
