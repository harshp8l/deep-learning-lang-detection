import org.apache.spark.sql.functions._
import org.apache.spark.sql.Column


lazy val months = (((df select ($""MonthPrior"") distinct) sort 
($""MonthPrior"".asc)).rdd map (_.getAs[Int](0)) collect).toList

lazy val sliceSpec = List((0, 2, ""1-2""), (0, 3, ""1-3""), (0, 4, ""1-4""), (0, 5, ""1-5""), (0, 6, ""1-6""))

lazy val createGroup: List[Any] => ((Int, Int, String) => Column) = sliceMe => (start, finish, aliasName) =>
  sliceMe slice (start, finish) map (value => col(value.toString)) reduce (_ + _) as aliasName

lazy val grouper = createGroup(months).tupled

lazy val groupedCols = sliceSpec map (group => grouper(group))

val pivoted = df groupBy ($""ID"") pivot (""MonthPrior"") agg (sum($""Amount""))

val writeMe = pivoted select ((pivoted.columns map col) ++ (groupedCols): _*)

z.show(writeMe sort ($""ID"".asc))
