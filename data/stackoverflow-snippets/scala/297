val ss = SparkSession.builder().master("local[*]").getOrCreate()
    val sc = ss.sparkContext

    import ss.implicits._

    val pairRDD1 = sc.parallelize(List(("cat", 2,9999), ("girl", 5,8888), ("book", 4,9999), ("Tom", 12,6666)))
    val pairRDD2 = sc.parallelize(List(("cat", 2,9999), ("cup", 5,7777), ("mouse", 4,3333), ("girl", 12,1111)))

    val df1 = pairRDD1.toDF
    val df2 = pairRDD2.toDF

    val joined = df1.join(df2, df1.col("_1") === df2.col("_1"),"fullouter")
    joined.show()
