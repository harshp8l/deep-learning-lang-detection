val df = Seq(
  (""aa"", ""271_a.C"", 1, 4675),
  (""aa"", ""271_a.C"", 1, 4400),
  (""aa"", ""271_a.C"", 1, 4600),
  (""aa"", ""Chiron_Elias_Krase"", 1, 4694),
  (""aa"", ""Chiron_Elias_Krase"", 1, 4500)
).toDF(""project"", ""title"", ""request_num"", ""return_size"")

import org.apache.spark.sql.functions._
import org.apache.spark.sql.Row

val rdd = df.rdd.
  map{ case Row(_, title: String, _, _) => (title, 1) }.
  reduceByKey(_ + _)

rdd.collect
// res1: Array[(String, Int)] = Array((Chiron_Elias_Krase,2), (271_a.C,3))
