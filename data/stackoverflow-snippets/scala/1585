import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.ml.feature.Bucketizer

scala> val df = spark.range(20).withColumn(""age"", round(rand()*90).cast(IntegerType))
df: org.apache.spark.sql.DataFrame = [id: bigint, age: int]

scala> df.show
+---+---+
| id|age|
+---+---+
|  0| 58|
|  1| 57|
|  2| 43|
|  3| 62|
|  4| 18|
|  5| 70|
|  6| 26|
|  7| 54|
|  8| 70|
|  9| 42|
| 10| 38|
| 11| 79|
| 12| 77|
| 13| 14|
| 14| 87|
| 15| 28|
| 16| 15|
| 17| 59|
| 18| 81|
| 19| 25|
+---+---+
