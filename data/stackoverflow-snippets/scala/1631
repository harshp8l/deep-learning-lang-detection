// IMPORT DEPENDENCIES
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.{SQLContext, Row, DataFrame, Column}
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.{Pipeline, PipelineModel}

// Create first example dataframe
val exampleDF = spark.createDataFrame(Seq(
  (1, 1, 2, 3, 8, 4, 5, 1, 3, 2, 0, 4, 2, 8, 1, 1, 2, 3, 8, 4, 5),
  (2, 4, 3, 8, 7, 9, 8, 2, 3, 3, 2, 6, 5, 4, 2, 4, 3, 8, 7, 9, 8),
  (3, 6, 1, 9, 2, 3, 6, 3, 8, 5, 1, 2, 3, 5, 3, 6, 1, 9, 2, 3, 6),
  (4, 7, 8, 6, 9, 4, 5, 4, 9, 8, 2, 4, 9, 2, 4, 7, 8, 6, 9, 4, 5),
  (5, 9, 2, 7, 8, 7, 3, 5, 3, 4, 8, 0, 6, 2, 5, 9, 2, 7, 8, 7, 3),
  (6, 1, 1, 4, 2, 8, 4, 6, 3, 9, 8, 8, 9, 3, 6, 1, 1, 4, 2, 8, 4)
)).toDF(""uid"", ""col1"", ""col2"", ""col3"", ""col4"", ""col5"", 
        ""col6"", ""col7"", ""col8"", ""col9"", ""colA"", ""colB"", 
        ""colC"", ""colD"", ""colE"", ""colF"", ""colG"", ""colH"", 
        ""colI"", ""colJ"", ""colK"")

// Create multiple column lists using the sliding method
val Array(colList1, colList2, colList3, colList4) = exampleDF.columns.filter(_ != ""uid"").sliding(5,5).toArray

// Create a vector assembler for each column list
val colList1_assembler = new VectorAssembler().setInputCols(colList1).setOutputCol(""colList1_vec"")
val colList2_assembler = new VectorAssembler().setInputCols(colList2).setOutputCol(""colList2_vec"")
val colList3_assembler = new VectorAssembler().setInputCols(colList3).setOutputCol(""colList3_vec"")
val colList4_assembler = new VectorAssembler().setInputCols(colList4).setOutputCol(""colList4_vec"")

// Create a vector assembler using column list vectors as input
val features_assembler = new VectorAssembler().setInputCols(Array(""colList1_vec"",""colList2_vec"",""colList3_vec"",""colList4_vec"")).setOutputCol(""features"")

// Create the pipeline with column list vector assemblers first, then the final vector of vectors assembler last
val pipeline = new Pipeline().setStages(Array(colList1_assembler,colList2_assembler,colList3_assembler,colList4_assembler,features_assembler))

// Fit and transform the data
val featuresDF = pipeline.fit(exampleDF).transform(exampleDF)

// Get the number of features in ""features"" vector
val featureLength = (featuresDF.schema(featuresDF.schema.fieldIndex(""features"")).metadata.getMetadata(""ml_attr"").getLong(""num_attrs""))

// Print number of features in ""features vector""
print(featureLength)
