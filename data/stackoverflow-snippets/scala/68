import org.apache.spark.sql.functions._

val df = Seq(
  (1, "22"),
  (1, "22"),
  (2, "22"),
  (2, "22"),
  (2, "22")
).toDF("id", "type")

val pivotCols = Map("22"->"a_type", "33"->"b_type")

val pivotDF = df.groupBy("id").pivot("type").agg(count($"type")).na.fill(0)

val resultDF = pivotCols.keys.foldLeft( pivotDF )( (df, c) => 
  if ( df.columns contains c ) df.withColumnRenamed(c, pivotCols(c)) else 
    df.withColumn(pivotCols(c), lit(0))
)

resultDF.show
// +---+------+------+
// | id|a_type|b_type|
// +---+------+------+
// |  1|     2|     0|
// |  2|     3|     0|
// +---+------+------+
