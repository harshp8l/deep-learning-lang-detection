val df = sc.parallelize(Seq((""1:a:x|y|z""), (""2:b:y|z""),  (""3:c:x""),(""4:d:w|x"")))
 df.collect
//flat map 
val df1=df.flatMap {
  row => 
   val Array(col1, col2, col3) = row.split(':')
   col3.split('|').map(value => (col1, col2, value) )
}

df1.collect
//filer as per requirments
val df2=df1.toDF(""col1"",""col2"",""col3"")
df2.show()
//df2.createOrReplaceTempView(""TempTable"")
//val countDF = spark.sqlContext.sql(""SELECT col1,col2,col3, MIN(col1) FROM TempTable GROUP BY  col1,col2,col3"").show()

val w = Window.partitionBy($""col1"").orderBy($""col1"".desc)

val dfTop = df2.withColumn(""rn"", row_number.over(w)).where($""rn"" === 1).drop(""rn"").orderBy($""col1"".asc)

dfTop.show
