  //dummy data 
  val d1 = spark.sparkContext.parallelize(Seq(
    (""webservice1"", 80, 1),
    (""webservice1"", 87, 2),
    (""webservice1"", 283, 1),
    (""webservice2"", 77, 2),
    (""webservice2"", 80, 1),
    (""webservice2"", 81, 1),
    (""webservice3"", 63, 3),
    (""webservice3"", 145, 1),
    (""webservice4"", 167, 1),
    (""webservice4"", 367, 2),
    (""webservice4"", 500, 1)
  )).toDF(""webService_Name"",""responseTime"",""numberOfSameTime"")

  //window functionn 
  val window = Window.partitionBy(""webService_Name"").orderBy($""webService_Name"")
    .rowsBetween(Long.MinValue, 0)

  // create new column for Result
  d1.withColumn(""Result"", sum(""numberOfSameTime"").over(window)).show(false)
