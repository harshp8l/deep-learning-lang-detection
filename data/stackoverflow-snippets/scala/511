val tempId = df.select("id")  //creating temp table of id for inner join later on

import org.apache.spark.sql.functions._
df.select(col("authors"), explode(col("references")).as("id"))  // selecting authors and exploding references column so that each element of array in reference column is exploded to each row
  .join(tempId, Seq("id"))   // inner join the exploded dataframe with the temp table created above, this will filter out not matching id rows
  .select("authors")         // selecting only  the authors column
  .distinct()                // optional step for removing duplicate rows if any
