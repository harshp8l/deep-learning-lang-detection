import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.expressions.UserDefinedFunction
import org.apache.spark.sql.functions._ // for udf and lit

trait Foo {
  def name: String
  def calc(n: Int): Int
}
class Bar extends Foo {
  def name: String = "Bar"
  def calc(n: Int): Int = n + 1
}
class Baz extends Foo{
  def name: String = "Baz"
  def calc(n: Int): Int = n * 2
}

val foo1: Foo = new Bar()
val foo2: Foo = new Baz()

def process(df: DataFrame, foo: Foo): DataFrame = {
  // Pass exact implementation to udf function
  val udf1: UserDefinedFunction = udf(foo.calc _) // _ to make it partially applied
  df.withColumn("calc", udf1(col("n")))
    .withColumn("name", lit(foo.name))
}

val data: Seq[Int] = Seq(1, 2, 3)
val df: DataFrame = data.toDF("n")

val r1 = process(df, foo1)
println("foo1: ")
r1.show()

val r2 = process(df, foo2)
println("foo2: ")
r2.show()
