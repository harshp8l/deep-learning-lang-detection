val ds = spark.createDataset(1 to 1000)
import scala.util.{Try, Success, Failure}
//simulates intermittent failure
def writeToCassandra(i:Int):Either[List[String], Unit] = if(i % 11 == 0) Left(List(s"fail $i")) else Right(())
//in stream rdd
//read offset
val succeded = ds.rdd.map(writeToCassandra).reduce {
  case (Right(_), Right(_)) => Right(())
  case (Right(_), Left(err)) => Left(err)
  case (Left(err), Right(_)) => Left(err)
  case (Left(err1), Left(err2)) => Left(err1 ::: err2)
}

succeded match {
  case Right(_) => //commit offsets
  case Left(errList) => // log errors and clean up messages by e.g. writing them to an err topic and then commiting offsets or whatever you want
}
