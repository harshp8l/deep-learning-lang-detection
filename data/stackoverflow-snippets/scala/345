//1)csv file available in xl sheet
val df = sqlContext
  .read
  .format("com.databricks.spark.csv")
  .option("header", true)
  .load("path to the csv file")

df.show(false)
  //+-----+-----+------+
  //|brand|month|price |
  //+-----+-----+------+
  //|abc  |jan  | -    |
  //|abc  |feb  | 29   |
  //|abc  |mar  | -    |
  //|abc  |apr  | 45.23|
  //|bb-c |jan  | 34   |
  //|bb-c |feb  |-35   |
  //|bb-c |mar  | -    |
  //+-----+-----+------+  

import org.apache.spark.sql.functions._
//2)trim the extra spaces in price
//3)replace non-numeric(" -   ") with zero
df.withColumn("price", regexp_replace(col("price"), "[\\s+a-zA-Z- :]", "").cast("double"))
//4)sum the price group by brand    
    .groupBy("brand")
    .agg(sum("price").as("price_sum"))
    .show(false)
//+-----+-----------------+
//|brand|price_sum        |
//+-----+-----------------+
//|abc  |74.22999999999999|
//|bb-c |69.0             |
//+-----+-----------------+
