val df = spark.read.csv("/path/to/csvfile")

+--------+----------------------+-------------------------+
|_c0     |_c1                   |_c2                      |
+--------+----------------------+-------------------------+
|10366565|01/03/2016 01:50:00 PM|SCHOOL, PRIVATE, BUILDING|
|10366700|01/04/2016 12:30:00 PM|SCHOOL, PRIVATE, BUILDING|
+--------+----------------------+-------------------------+

// A UDF function that converts ",\s*" to "|"
def commaToPipe = udf( (s: String) =>
  """,\s*""".r.replaceAllIn(s, "|")
)

df.select($"_c0", commaToPipe($"_c2")).show(truncate=false)
+--------+-----------------------+
|_c0     |UDF(_c2)               |
+--------+-----------------------+
|10366565|SCHOOL|PRIVATE|BUILDING|
|10366700|SCHOOL|PRIVATE|BUILDING|
+--------+-----------------------+
