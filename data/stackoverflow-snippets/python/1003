import .....

class SeekerSpider(CrawlSpider):

name = 'seeker'
allowed_domains = ['info.mzalendo.com']
start_urls = ['http://info.mzalendo.com/position/member-national-assembly/?page=1']
main_url = 'http://info.mzalendo.com/position/member-national-assembly/'
urls = []
retrieving = False

def parse(self, response):
    .......
    #  All the above code in between.
    .......

    #should run once all urls have been found
    for url in self.urls:
        #get content for url to be parsed. USE CALLBACK
        yield scrapy.Request(url, callback=self.parse_url)

def parse_url(self, response):
    #Do whatever you want with the response of desired url.
