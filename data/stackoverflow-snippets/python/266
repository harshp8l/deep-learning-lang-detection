from __future__ import division
import re
import itertools
import re
import hashlib

def splitFile(lines,splitvalue):
    documents={};
    documentCount=1
    dcmnt="";
    for line in lines:
        dcmnt+=line;
        if (line.__contains__(splitvalue)):
            key="documents"+(str)(documentCount);
            documents[key]=dcmnt;
            dcmnt="";
            documentCount=documentCount+1;
    return documents;

def findSearchSaveMostRepeated(myHash, documentswords):
    tempvalue=0
    for ii in range(0, myHash.__len__()):

        if myHash[documentswords[ii]] > tempvalue :
            tempvalue= myHash[documentswords[ii]]
            x=documentswords[ii]
        if ii + 1 == myHash.__len__():
            #if tempvalue < myHash[documentswords[ii+1]]:
                myHash[x] = 0;
                myLastHash[x] = tempvalue
                return myLastHash[x]





readFile=open("reuters.txt","r");
lines=readFile.readlines();
readFile.close();
alldocuments=splitFile(lines, "</REUTERS>");
#if (alldocuments.count()!=0):
#    print("");
readstopwordFile=open("stopwords.txt","r");
lines2=readstopwordFile.readlines();
readstopwordFile.close();
allstopwords=splitFile(lines2, "\n");
#if (lines.count()!=0):
#    print("");
readFile3=open("reuterdeneme.txt","r");
lines3=readFile3.readlines();
readFile3.close();
alldocumentssecond=splitFile(lines3, "</REUTERS>");

documentswords = []
with open('reuterdeneme.txt','r') as f:  #reading a text file and splitting it into single words
    for line in f:
        for word in line.split():
            documentswords.append(word)
print(documentswords[6]+"example document value")
stopwords=[]
with open('stopwords.txt','r') as f:  #reading a text file and splitting it into single words
    for line in f:
        for word in line.split():
            stopwords.append(word)

print(stopwords[9]+"example stopword value");

#print(stopwords.__len__()) # length of it
numberofwords=documentswords.__len__()
print(numberofwords);

myHash={}
tempofStopwords = []
countTEMP=[]

for i in range(0,documentswords.__len__()):
    count=0;
    for ii in range(0,documentswords.__len__()):


        if documentswords[i]==documentswords[ii]:
            count=count+1;
        if ii+1  == documentswords.__len__():
            print("word")
            print(documentswords[i]);
            print("tanesi");
            print(count);
            tempofStopwords.append(documentswords[i]);
            countTEMP.append(count);
            myHash[documentswords[i]] = count  #words' count



#for i in range(0, myHash.__len__()):
print("hash")
# print(myHash[documentswords[6]]); # I am getting count value with this

print(myHash.keys()); # my key values in myHash


myLastHash={}

tempvalue=0;
print(myHash.__len__())

for i in range(0,100):

    findSearchSaveMostRepeated(myHash,documentswords )  # i am getting the most repeated 100 stopwords


print("my last hash")
print(myLastHash.keys());
print(myLastHash.__len__())
count1=0
count2=0
tempSameStopwords=[]
tempnotSameStopwords=[]
for i in range(0,stopwords.__len__()):
    print(stopwords[i])
    if True==myLastHash.keys().__contains__(stopwords[i]):
        #print("THERE IS")
        count1=count1+1;
        tempSameStopwords.append(stopwords[i])
    if False==myLastHash.keys().__contains__(stopwords[i]):
        #print("THERE IS NOT)
        count2=count2+1;
        tempnotSameStopwords.append(stopwords[i])




print("SAME STOPWORDS")
for i in range(0, tempSameStopwords.__len__()):
    print(tempSameStopwords[i])


print("DIFFERENT STOPWORDS")
for i in range(0, tempnotSameStopwords.__len__()):
    print(tempnotSameStopwords[i])

print("COUNT OF SAME STOPWORDS")
print(count1);
print("COUNT OF DIFFERENT STOP WORDS")
print(count2);



newdocumentswords=[]


print(alldocumentssecond.keys()); #got number of documents -> doc2 from reuterdeneme.txt



for i in range(0,stopwords.__len__()):           #inverted index part.. i am trying to do splitting all documents with single word in every line, and after that i will check which term in which document..
    for ii in range(1,3):
        x = 'file'
        y = ii.__str__();
        x = x + y.__str__();
        z = '.txt'
        m = x + z.__str__();
        #print(m);
        h='documents'.__str__()
        h=h+y;
        #print(h)
        xn = alldocuments[h]
        f = open(m, 'w')
        f.write(xn)
        f.close()
        with open(m, 'r') as f:  # reading a text file and splitting it into single words
            for line in f:
                for word in line.split():
                    newdocumentswords.append(word)
