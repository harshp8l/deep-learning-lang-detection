from bs4 import BeautifulSoup
import urllib
import csv
import time
from selenium import webdriver


count = 0   
browser = webdriver.Chrome()
browser.get("https://www.marketwatch.com/newsviewer")

while browser.find_element_by_tag_name('ol'):

    pageSource = browser.page_source
    soup = BeautifulSoup(pageSource, 'lxml')
    arkodiv = soup.find("ol", class_="viewport")
    browser.execute_script("document.documentElement.getElementsByClassName('viewport')[0].scrollTop = 999999")
    time.sleep(0.5)
    div = list(arkodiv.find_all('div', class_= "nv-details"))

    heading = set()
    Data_11 = list(soup.find_all("div", class_ = "nv-text-cont"))          

    datetime = list(arkodiv.find_all("li", timestamp = True))
    for sa in datetime:
        sh = sa.find("div", class_ = "nv-text-cont")
        if sh.find("a", class_ = True):
            di = sh.text.strip()
            di = di.encode('ascii', 'ignore').decode('ascii')
        else:
            continue
        print di
        heading.add((di))       
        count = count+1         


    if 'End of Results' in arkodiv:
        print 'end'
        break
    else:
        continue
    print count
