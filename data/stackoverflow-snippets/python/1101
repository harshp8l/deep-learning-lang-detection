driver = webdriver.Chrome()
driver.get('website.com')

# a dict where the key will be the section name
products = {}

# find all top-level sections
sections = driver.find_elements_by_css_selector('div.product-section')

# iterate over each one
for section in sections:
    # find the products that are children of this section
    # note the find() is based of section, not driver
    names = section.find_elements_by_css_selector('div.name')
    prices = section.find_elements_by_css_selector('div.price')
    colors = section.find_elements_by_css_selector('div.color')

    allNames = [name.text for name in names]
    allPrices = [price.text for price in prices]
    allColors = [color.text for color in colors]

    section_name = section.find_element_by_css_selector('div.section-title').text

    # add the current scraped section to the products dict
    # I'm leaving it to you to match the name, price and color of each ;)

    products[section_name] = {'names': allNames,
                              'prices': allPrices,
                              'colors': allColors,}

# and here's how to access the result

# get the 1st name in a section:
print(products['Product section name']['names'][0])  # will output "Wooden Table"

# iterate over the sections and products:
for section in products:
    print('Section: {}'.format(section))
    print('All prices in the section:')
    for price in section['prices']:
       print(price)
