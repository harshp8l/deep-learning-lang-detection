# -*- coding: utf-8 -*-
import scrapy


class sth(scrapy.Spider):
    name = 'sth'
    allowed_domain = ['example.com']
    start_urls = [ 
         'https://www.example.com/url1/',
         'https://www.example.com/url2/',
         'https://www.example.com/url3/',
    ]

def parse(self, response):
          for content in response.css('div#content'):
               yield {
                    'data1': content.css('li#name2::text').extract(),
                    'data2': content.css('li#name1::text').extract(),
    }
