void sparkProcess(){
    SparkConf sparkConf = new SparkConf().setAppName(""name"");
    JavaSparkContext sc = new JavaSparkContext(sparkConf)
    Configuration hadoopConf = sc.hadoopConfiguration();
    hadoopConf.set(""fs.s3.awsAccessKeyId"", awsAccessKey);
    hadoopConf.set(""fs.s3.awsSecretAccessKey"", awsSecretKey);
    String folderPath = ""s3://bucket/output/folder"";
    String mergedFilePath = ""s3://bucket/output/result.txt"";
    BatchFileUtil.copyMerge(hadoopConf, folderPath, mergedFilePath);
}    

public static boolean copyMerge(Configuration hadoopConfig, String srcPath, String dstPath) throws IOException, URISyntaxException {
    FileSystem hdfs = FileSystem.get(new URI(srcPath), hadoopConfig);
    return FileUtil.copyMerge(hdfs, new Path(srcPath), hdfs, new Path(dstPath), false, hadoopConfig, null);
}
